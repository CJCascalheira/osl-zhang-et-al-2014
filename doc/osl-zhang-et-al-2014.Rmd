---
title: "OSL Factorial ANOVA in R Using Data from Zhang et al. (2014)"
author: "Cory J. Cascalheira"
date: "December 3, 2018"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/GitHub/osl-zhang-et-al-2014/src")
```

# Open Stats Lab
___
Kevin P. McIntyre developed this amazing resource for students of psychology. Check out [Open Stats Lab](https://sites.trinity.edu/osl/) for a collection of all activities.

Each activity includes an article from *Psychological Science*, a data set, and an activity to complete in SPSS. However, if you are an open source fanatic, you could also complete the activity in [JASP](https://jasp-stats.org/). For tips on how to use JASP, check out [this resource](https://osf.io/t56kg/) created by Buchanan, Hopke, and Donaldson (2018).

I prefer to get my hands deep into the data. Dr. McIntyre does not *yet* offer an R activity to accompany the work of [Zhang et al. (2014)](https://journals.sagepub.com/stoken/default+domain/2CauuvIqpaIUiIdXSWh4/full), so here is one possible solution written in R.

# Analysis
___
I will perform assumption checks for each test prior to running it. We already know that the data meet all assumptions, otherwise the authors would have used a different analytic approach. However, checking the assumptions is helpful because:

1. reproducibility and accuracy can be verified; and
2. if you are a student, then you should form the habit of testing assumptions.

This analysis will follow the data science workflow advocated by [Garrett Grolemund and Hadley Wickham](https://r4ds.had.co.nz/introduction.html). First, we will set-up our session and import the data. Then, we must clean the data. Next, we will transform, model, and visualize the data to understand it. Finally, we will communicate our findings.

## Import
___
Let's load the packages necessary for this analysis into our workspace.

```{r message = FALSE}
library(psych) # describe data
library(broom) # coefficient-level information
library(car) # Levene's test, Anova function
library(nlme) # repeated measures ANOVA
library(multcomp) # post-hoc measures
library(tidyverse) # utility and visualization
```

We can import the dataset using a relative path because our working directory is set.

```{r message = FALSE}
zhang <- read_csv("../data/Zhang et al. 2014 Study 3.csv")
```

## Clean
___
What do the data look like?

```{r}
glimpse(zhang)
```

For this analysis, we only need the first seven variables. Let's `select()` them using `snake_case` and abbreviation.

```{r}
zhang_clean <- zhang %>%
  select(
    condition = Condition,
    t1_extra = T1_Extraordinariness,
    t2_extra = T2_Extraordinariness,
    t1_curious = T1_Predicted_Curious,
    t2_curious = T2_Actual_Curious,
    t1_interest = T1_Predicted_Interest_Composite,
    t2_interest = T2_Actual_Interest_Composite
  )
```

Make condition a between-subjects factor with appropriate labels. Since the ordinary condition is mentioned first throughout the article, we can assume that 1 corresponds to ordinary. If our analyses do not match those reported in the paper, then it will be important to return to this step.

```{r}
zhang_clean <- within(zhang_clean, {
  condition <- factor(condition, labels = c("ordinary", "extraordinary"))
})
```

How many participants are in each condition?

```{r}
zhang_clean %>% count(condition)
```

Thus, we have an unbalanced design.

Let's split the data by condition to calculate the standard error later with `psych::describe`.

```{r}
ordinary <- zhang_clean %>% filter(condition == "ordinary")
extraordinary <- zhang_clean %>% filter(condition == "extraordinary")
```

## Understand
___
This study is truly a factorial design. It combines within-subjects and between-subjects factors. We must perform repeated measures ANOVA because [all participants received all conditions](http://www.discoveringstatistics.com/docs/repeatedmeasures.pdf).

We will test for mean differences between conditions and between time points, running post-hoc tests to discover which condition/time combination is significant. The null and altnerative hypotheses are:

$$H_0: \mu_1 = \mu_2 = \mu_3 = \dots = \mu_k \\ H_1: \text{at least two means are significantly different}$$

The **repeated measures mixed ANOVA** has [six assumptions](https://statistics.laerd.com/spss-tutorials/mixed-anova-using-spss-statistics.php), two of which are met through experimental design:

1. **Continuous dependent variable** at the interval or ratio level.
    - In this analysis, there is more than one dependent variable, but we shall *only* test one at a time (i.e., no need for MANOVA).

2. **Categorical independent variables** as factors with two or more levels that can be:
    - *within-subjects*, such as the two different time points, or
    - *between-subjects*, such as two different conditions.

3. **No significant outliers** in any level combination of the within-subjects factor or between-subjects factor. Outliers skew data, distort the differences between related groups, and affect normality. 

4. **Approximately normal distribution** of the dependent variable for each level combination of both the within-subjects and between-subjects factors. Since ANOVA is robust, mild violations of normality can be tolerated if the number of observations is uniform across levels, or when the sample size is large, `n >= 30`. The assumption assesses the distribution of residuals with the Shapiro-Wilk test, density curves, Q-Q plots, or histograms.

5. **Homogeneity of variances** for each combination of the groups of the two within-subjects and between-subjects factors. Assessed with Levene's test.

6. **Sphericity**, which states that the differences in variances between the related groups of the within-subjects factor for all groups of the between-subjects factor (i.e., dependent variable) are equal. [This assumption](https://www.sheffield.ac.uk/polopoly_fs/1.531222!/file/MASH_repeated_measures_ANOVA_SPSS.pdf) *must* be met. It is assessed with Mauchley's test. If *p* > 0.05, sphericity can be assumed. If the test is significant, then use the Greenhouse-Geisser correction.

### Auxiliary Analyses {.tabset .tabset-pills}

In addition to computing repeated measures ANOVA and assumption tests, we will calculate the confidence intervals and effect sizes of the dependent variables (i.e., extraordinariness, curiosity, interest) for each level combination of both the within-subjects and between-subjects factors.

#### Confidence Intervals

The original study reports **confidence intervals** at the 95% level. This assumes an alpha of 0.05. The critical value at the 95% confidence interval is 1.96. But if you were not sure, here is [how to calculate the critical value in R](http://www.stat.ucla.edu/~rgould/110as02/bsci) for the lower bound.

```{r}
# Set significance level
alpha <- 0.05

# Calculate critical value for lower bound 
qnorm(alpha/2)
```

The critical value for the upper bound is the opposite of the lower bound, so simply switch the signs. Alternatively, you could add 0.025 (i.e., alpha / 2) to the confidence level and run `qnorm()` again. This would be useful for writing functions or reproducible scripts.

```{r}
qnorm(0.95 + (alpha / 2))
```

Since we will calculate the confidence intervals for the sampling distribution of the sample mean, we must subtract and add the margin of error to the mean of each between-subjects factor. The **margin of error** is the critical value multiplied by the standard error of the sampling distribution of the sample mean.

The general equation to manually calculate the confidence interval is:

$$\bar{x} \pm z^*(SE_\bar{x})$$

You could save the absolute value of the critical value as an R object for use later. In this analysis, 1.96 will be preferred.

#### Effect Size

The effect size of interaction terms in a repeated measures ANOVA is given by partial eta-squared. The general equation for this statistic is

$$\eta_p^2 = \frac{SS_\text{predictor}}{SS_\text{predictor} + SS_\text{residuals}},$$

where SS stands for *sum of squares*.

### Manipulation Check of Extraordinariness {.tabset .tabset-pills}

Do participants in the extraordinary condition actually perceive Valentine's Day to be more extraordinary than participants rating a normal day?

We can answer this with a simple one-way between-groups ANOVA.

**Note**: the *F*-value and partial eta-squared will not match the statistics reported in the original paper.

```{r}
# Create analysis of variance
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)

# Summarize one-way ANOVA
Anova(t1_extra_aov)

# Descriptive statistics
zhang_clean %>%
  group_by(condition) %>%
  summarize(
    mean = mean(t1_extra),
    sd = sd(t1_extra),
    n = n(),
    upper = mean - (1.96 * (sd / sqrt(n))),
    lower = mean + (1.96 * (sd / sqrt(n)))
  )

# Tidy aov object
(t1_extra_tidied <- tidy(t1_extra_aov))

# Partial eta-squared
(t1_extra_tidied[1, 3] / (t1_extra_tidied[1, 3] + t1_extra_tidied[2, 3])) %>%
  pull()
```

A manipulation check at Time 1 revealed that participants assigned to the extraordinary condition perceived their experience with a lover to be more extraordinary (*M* = 4.35, *SD* = 1.38, 95% CI = [4.02, 4.68]) than those in the ordinary condition (*M* = 2.73, *SD* = 1.42, 95% CI = [2.39, 3.08]), *F*(1, 128) = 43.43, *p* < .001, $\eta_p^2 = .25$. 

#### Outliers?
```{r}
ggplot(zhang_clean, aes(x = condition, y = t1_extra)) +
  geom_boxplot()
```

No outliers in dependent variable for either condition.

#### Normality?
```{r}
shapiro.test(residuals(t1_extra_aov))
```

Since *p* = .019, it is less than the significance level and we reject the null hypothesis of this test: the data are not normally distributed. However, remember that the one-way ANOVA is robust and can withstand violations of normality.

Besides, each between-subjects group has a sample size above 30, making this assumption [more-or-less met](http://www2.psychology.uiowa.edu/faculty/mordkoff/GradStats/part%201/I.07%20normal.pdf).

#### Homoscedasticity?
```{r}
leveneTest(t1_extra ~ condition, data = zhang_clean)
```

The *F*-value does not exceed the critical values (*p* = .547), so we accept the null hypothesis: the variances are homogenous.

### Extraordinariness Over Time by Condition {.tabset .tabset-pills}

#### Outliers?

#### Normality?

#### Homoscedasticity?

#### Sphericity?

### Curiosity Over Time by Condition {.tabset .tabset-pills}

#### Outliers?

#### Normality?

#### Homoscedasticity?

#### Sphericity?

### Interest Over Time by Condition {.tabset .tabset-pills}

#### Outliers?

#### Normality?

#### Homoscedasticity?

#### Sphericity?

### Visualize

## Communicate
___
A manipulation check at Time 1 revealed that participants assigned to the extraordinary condition perceived their experience with a lover to be more extraordinary (*M* = 4.35, *SD* = 1.38, 95% CI = [4.02, 4.68]) than those in the ordinary condition (*M* = 2.73, *SD* = 1.42, 95% CI = [2.39, 3.08]), *F*(1, 128) = 43.43, *p* < .001, $\eta_p^2 = .25$.

# Acknowledgements
___
I am thankful for my advisor, Dr. Brandt A. Smith for introducing me to R, JASP, and OSL. The discipline of psychology is advocating for preregistered, open materials. His encouragement to utilize open data and open source software has positioned me in the middle of the reproducible movement.

I would still be clicking checkboxes and dropdowns to analyze data if it were not for [DataCamp](https://www.datacamp.com), [Rose Maier](https://rstudio-pubs-static.s3.amazonaws.com/65059_586f394d8eb84f84b1baaf56ffb6b47f.html), [Alboukadel Kassambara](http://www.sthda.com/english/wiki/r-software), [Jonathan Baron](https://www.sas.upenn.edu/~baron/from_cattell/rpsych/rpsych.html#htoc60), and the team behind [personality-project](http://personality-project.org/r/r.guide.html#withinone).

## Dependencies
This activity was completed using RStudio.

```{r}
devtools::session_info()
```