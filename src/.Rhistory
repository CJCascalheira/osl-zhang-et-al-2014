twins_sigma <- model %>%
# Get model-level information
glance() %>%
# Pull out sigma
pull(sigma)
# Find the natural variability of the points around the prediction line
predictions2 <- predictions %>%
# Calculate the std err of the predictions
mutate(std_err_of_predictions = sqrt(twins_sigma^2 + .se.fit^2))
# Prediction interval
predictions3 <- predictions2 %>%
# Calculate the prediction intervals
mutate(
lower_response_prediction = .fitted - critical_value * std_err_of_predictions,
upper_response_prediction = .fitted + critical_value * std_err_of_predictions
)
# Visualize prediction intervals
ggplot() +
geom_point(aes(x = Biological, y = Foster), data = twins) +
geom_smooth(aes(x = Biological, y = Foster), data = twins, method = "lm") +
# Add a ribbon layer
geom_ribbon(aes(x = Biological, ymin = lower_response_prediction,
ymax = upper_response_prediction),
data = predictions3, alpha = 0.2, fill = "red")
# Plot relationship
ggplot(RailTrail, aes(x = hightemp, y = volume)) +
geom_point()
# Augment linear model
ride_lm_augmented <- augment(ride_lm)
# Plot residuals versus fitted values
ggplot(ride_lm_augmented, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
homes <- read_csv("J:/sample_data/la-homes.csv")
lm(log(price) ~ log(sqft), data = homes) %>%
tidy()
lm(log(price) ~ log(bath), data = homes) %>%
tidy()
corr_homes <- homes %>% select(price, bath, sqft)
corrplot(corr_homes)
corr_homes
cor(corr_homes)
corrplot(cor(corr_homes))
corr_homes <- homes %>% select(price, bath, sqft)
corr_homes <- cor(corr_homes)
corrplot(corr_homes, type = "lower")
corr_homes <- homes %>% select(price, bath, sqft)
corr_homes <- cor(corr_homes)
corrplot(corr_homes, type = "lower")
corr_homes <- homes %>% select(price, bath, sqft)
corr_homes <- cor(corr_homes)
corrplot,mixed(corr_homes)
corr_homes <- homes %>% select(price, bath, sqft)
corr_homes <- cor(corr_homes)
corrplot.mixed(corr_homes)
lm(log(price) ~ log(sqft) + log(bath), data = homes) %>%
tidy()
nyc_rest <- read_csv("J:/sample_data/nyc_restaurant.csv")
nyc_rest <- read_csv("J:/sample_data/nyc_restaurant.csv")
lm(Price ~ Service, data = nyc_rest) %>%
tidy()
lm(Price ~ Service + Food + Decor, data = nyc_rest) %>%
tidy()
sqrt(
(0.55*0.45) / 100
)
0.05*2.58
.55-0.129
.55+0.129
0.95-0.9495
0.95-0.9505
1-0.334
sqrt(
(0.334*0.666) / 1000
)
0.015*1.645
0.334-0.025
0.334+0.025
96/200
1-(96/200)
sqrt(
(0.48*0.52) / 200
)
SEp <- sqrt(
(0.48*0.52) / 200
)
SEp * 1.645
0.4*0.6
0.05^2
1.96^2
0.0025/3.8416
3.8416/0.0025
1536.64*0.24
SEp <- sqrt(
(0.5*0.5)/1000
)
SEp * 1.96
SEp <- sqrt(
(0.5*0.5)/4000
)
SEp * 1.96
0.9*0.1
1.96/0.02
98^2
9604*0.09
# Set working directory
setwd("~/GitHub/osl-zhang-et-al-2014/src")
# Import data
zhang <- read_csv("../data/Zhang et al. 2014 Study 3.csv")
# Load dependencies
library(tidyverse)
# Import data
zhang <- read_csv("../data/Zhang et al. 2014 Study 3.csv")
View(zhang)
####### CLEAN DATA #######
glimpse(zhang)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/GitHub/osl-zhang-et-al-2014/src")
glimpse(zhang)
# Select and rename variables of interest
zhang %>%
select(
condtion = Condition
)
# Select and rename variables of interest
zhang %>%
select(
condtion = Condition,
t1_extra = T1_Extraordinariness,
t2_extra = T2_Extraordinariness,
t1_curious = T1_Predicted_Curious,
t2_curious = T2_Actual_Curious,
t1_interest = T1_Predicted_Interest_Composite,
t2_interest = T2_Actual_Interest_Composite
)
# Select and rename variables of interest
zhang_clean <- zhang %>%
select(
condtion = Condition,
t1_extra = T1_Extraordinariness,
t2_extra = T2_Extraordinariness,
t1_curious = T1_Predicted_Curious,
t2_curious = T2_Actual_Curious,
t1_interest = T1_Predicted_Interest_Composite,
t2_interest = T2_Actual_Interest_Composite
)
```{r}
zhang_clean <- zhang %>%
select(
condtion = Condition,
t1_extra = T1_Extraordinariness,
t2_extra = T2_Extraordinariness,
t1_curious = T1_Predicted_Curious,
t2_curious = T2_Actual_Curious,
t1_interest = T1_Predicted_Interest_Composite,
t2_interest = T2_Actual_Interest_Composite
)
condition <- factor(condition, labels = c("ordinary", "extraordinary"))
# Condition as factor
within(zhang_clean, {
condition <- factor(condition, labels = c("ordinary", "extraordinary"))
})
# Condition as factor
within(zhang_clean, {
condition <- factor(condition, labels = c("ordinary", "extraordinary"))
})
View(zhang_clean)
# Select and rename variables of interest
zhang_clean <- zhang %>%
select(
condition = Condition,
t1_extra = T1_Extraordinariness,
t2_extra = T2_Extraordinariness,
t1_curious = T1_Predicted_Curious,
t2_curious = T2_Actual_Curious,
t1_interest = T1_Predicted_Interest_Composite,
t2_interest = T2_Actual_Interest_Composite
)
# Condition as factor
within(zhang_clean, {
condition <- factor(condition, labels = c("ordinary", "extraordinary"))
})
zhang_clean
zhang_clean <- within(zhang_clean, {
condition <- factor(condition, labels = c("ordinary", "extraordinary"))
})
zhang_clean <- zhang %>%
select(
condition = Condition,
t1_extra = T1_Extraordinariness,
t2_extra = T2_Extraordinariness,
t1_curious = T1_Predicted_Curious,
t2_curious = T2_Actual_Curious,
t1_interest = T1_Predicted_Interest_Composite,
t2_interest = T2_Actual_Interest_Composite
)
zhang_clean <- within(zhang_clean, {
condition <- factor(condition, labels = c("ordinary", "extraordinary"))
})
zhang_clean
zhang_clean %>% count(condition)
zhang_clean %>% count(condition)
# Filter by condition
ordinary <- zhange_clean %>% filter(condition == "ordinary")
# Filter by condition
ordinary <- zhang_clean %>% filter(condition == "ordinary")
extraordinary <- zhang_clean %>% filter(condition == "extraordinary")
t.test(extraordinary$t1_extra, ordinary$t1_extra,
paired = FALSE, var.equal = FALSE)
t.test(extraordinary$t1_extra, ordinary$t1_extra,
paired = FALSE, var.equal = TRUE)
summary(t.test(extraordinary$t1_extra, ordinary$t1_extra,
paired = FALSE, var.equal = TRUE))
library(broom)
tidy(t.test(extraordinary$t1_extra, ordinary$t1_extra,
paired = FALSE, var.equal = TRUE))
aov(t1_extra ~ condition, data = zhang_clean)
summary(aov(t1_extra ~ condition, data = zhang_clean))
?aov
options(contrasts = c("contr.sum", "contr.poly"))
summary(aov(t1_extra ~ condition, data = zhang_clean))
library(psych) # describe data
library(psych) # describe data
library(broom) # coefficient-level information
library(car) # Levene's test
library(nlme) # repeated measures ANOVA
library(multcomp) # post-hoc measures
library(tidyverse) # utility and visualization
Anova(aov(t1_extra ~ condition, data = zhang_clean), type = "III")
Anova(aov(t1_extra ~ condition, data = zhang_clean), type = "II")
aov(t1_extra ~ condition, data = zhang_clean)
aov(t1_extra ~ condition, data = zhang_clean)
Anova(aov(t1_extra ~ condition, data = zhang_clean))
Anova(aov(t1_extra ~ condition, data = zhang_clean), type = "III")
# Create analysis of variance object
oneway.test(t1_extra ~ condition, data = zhang_clean)
# Create analysis of variance object
oneway.test(t1_extra ~ condition, data = zhang_clean, var.equal = TRUE)
# Create analysis of variance object
oneway.test(t1_extra ~ condition, data = zhang_clean, var.equal = TRUE)
# Create analysis of variance object
aov(t1_extra ~ condition, data = zhang_clean)
Anova(t1_extra_aov)
# Create analysis of variance object
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
Anova(t1_extra_aov)
tidy(t1_extra_aov)
# Create analysis of variance object
t1_extra_aov <- lm(t1_extra ~ condition, data = zhang_clean)
Anova(t1_extra_aov)
tidy(t1_extra_aov)
summary(t1_extra_aov)
# Create analysis of variance object
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
Anova(t1_extra_aov)
tidy(t1_extra_aov)
# Create analysis of variance
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
# Summarize using type III sum of squares
Anova(t1_extra_aov, type = "III")
# Summarize using type III sum of squares
options(contrasts = c("contr.sum", "contr.poly"))
# Create analysis of variance
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
# Summarize using type III sum of squares
options(contrasts = c("contr.sum", "contr.poly"))
Anova(t1_extra_aov, type = "III")
ggplot(zhang_clean, aes(x = condition, y = t1_extra)) +
geom_boxplot()
ggplot(zhang_clean, aes(x = condition, y = t1_extra)) +
geom_boxplot()
ggplot(zhang_clean, aes(x = condition, y = t1_extra)) +
geom_boxplot()
#### Normality?
shapiro.test(residuals(t1_extra_aov))
plot(t1_extra_aov, 2)
shapiro.test(residuals(t1_extra_aov))
#### Homoscedasticity?
leveneTest(t1_extra_aov ~ condition, data = zhang_clean)
#### Homoscedasticity?
leveneTest(t1_extra ~ condition, data = zhang_clean)
leveneTest(t1_extra ~ condition, data = zhang_clean)
describe(extraordinary$t1_extra)
source('~/GitHub/osl-zhang-et-al-2014/src/zhang.R', echo=TRUE)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
upper = quantile(t1_extra, p = .975),
lower = quantile(t1_extra, p = .025)
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
upper = quantile(t1_extra, p = 1 - .975),
lower = quantile(t1_extra, p = .025)
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
upper = quantile(mean, p = .975),
lower = quantile(mean, p = .025)
)
tidy(t1_extra_aov, conf.int = TRUE)
tidy(t1_extra_aov, conf.int = TRUE, conf.level = .95)
alpha <- 0.95
qnorm(alpha/2)
qnorm(alpha)
qnorm(.975)
alpha <- 0.05
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
upper = mean - (1.96 * (sd / sqrt(nrow(t1_extra))))
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
upper = mean - (1.96 * (sd / sqrt(nrow(t1_extra))))
)
mean = mean(t1_extra),
sd = sd(t1_extra),
upper = mean(t1_extra - (1.96 * (sd(t1_extra) / sqrt(nrow(t1_extra))))
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
upper = mean(t1_extra) - (1.96 * (sd(t1_extra) / sqrt(nrow(t1_extra))))
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = nrow(t1_extra)
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = nrow(t1_extra)
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(t1_extra)
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n()
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n)))
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n))),
lower = mean - (1.96 * (sd / sqrt(n)))
)
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n))),
lower = mean + (1.96 * (sd / sqrt(n)))
)
mean(zhang_clean$t1_extra[condition == "extraordinary"]) + (1.96 * (sd(zhang_clean$t1_extra[condition == "extraordinary"]) / sqrt(nrow(zhang_clean$t1_extra[condition == "extraordinary"]))))
mean(zhang_clean$t1_extra) + (1.96 * (sd(zhang_clean$t1_extra) / sqrt(nrow(zhang_clean$t1_extra))))
emc <- zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n))),
lower = mean + (1.96 * (sd / sqrt(n)))
)
emc[2, 5]
emc[2, 5] %>% pill()
emc[2, 5] %>% pull()
qnorm(0.05/2)
# Set significance level
alpha <- 0.05
# Calculate critical value for lower bound
qnorm(0.05/2)
qnorm(0.95 + (alpha / 2))
# Create analysis of variance
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
# Summarize one-way ANOVA
Anova(t1_extra_aov)
# Descriptive statistics
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n))),
lower = mean + (1.96 * (sd / sqrt(n)))
)
# Create analysis of variance
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
# Summarize one-way ANOVA
Anova(t1_extra_aov)
# Descriptive statistics
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n))),
lower = mean + (1.96 * (sd / sqrt(n)))
)
# Partial eta-squared
tidy(t1_extra_tidied)
# Partial eta-squared
tidy(t1_extra_aov)
# Partial eta-squared
t1_extra_tidied <- tidy(t1_extra_aov)
# Partial eta-squared
(t1_extra_tidied <- tidy(t1_extra_aov))
# Create analysis of variance
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
# Summarize one-way ANOVA
Anova(t1_extra_aov)
# Descriptive statistics
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n))),
lower = mean + (1.96 * (sd / sqrt(n)))
)
# Tidy aov object
(t1_extra_tidied <- tidy(t1_extra_aov))
# Partial eta-squared
t1_extra_tidied[1, 3] / (t1_extra_tidied[1, 3] + t1_extra_tidied[2, 3])
# Partial eta-squared
(t1_extra_tidied[1, 3] / (t1_extra_tidied[1, 3] + t1_extra_tidied[2, 3])) %>% pull()
# Create analysis of variance
t1_extra_aov <- aov(t1_extra ~ condition, data = zhang_clean)
# Summarize one-way ANOVA
Anova(t1_extra_aov)
# Descriptive statistics
zhang_clean %>%
group_by(condition) %>%
summarize(
mean = mean(t1_extra),
sd = sd(t1_extra),
n = n(),
upper = mean - (1.96 * (sd / sqrt(n))),
lower = mean + (1.96 * (sd / sqrt(n)))
)
# Tidy aov object
(t1_extra_tidied <- tidy(t1_extra_aov))
# Partial eta-squared
(t1_extra_tidied[1, 3] / (t1_extra_tidied[1, 3] + t1_extra_tidied[2, 3])) %>%
pull()
zhang_clean
zhang_clean %>%
select(condition:t2_extra) %>%
gather(key = extra_time, value = extra_rating)
zhang_clean %>%
select(condition, t1_extra, t2_extra) %>%
gather(key = extra_time, value = extra_rating)
zhang_clean %>%
select(condition, t1_extra, t2_extra) %>%
gather(key = extra_time, value = extra_rating)
zhang_clean %>%
select(condition, t1_extra, t2_extra)
library(psych)
library(broom)
library(car)
library(nlme)
library(multcomp)
library(tidyverse)
zhang_clean
zhang_clean %>%
select(condition)
zhang_clean %>%
select()
